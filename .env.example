# Bijmantra Environment Configuration

# Application
APP_NAME=Bijmantra
APP_VERSION=preview-1
ENVIRONMENT=development

# ============================================
# USER CONFIGURATION
# ============================================
# Create your first user after setup:
#   make create-user
# Or use the registration API endpoint.

# Backend API
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
API_V2_PREFIX=/brapi/v2

# Frontend
FRONTEND_PORT=5173
VITE_API_BASE_URL=http://localhost:8000

# Database (PostgreSQL)
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_USER=bijmantra_user
POSTGRES_PASSWORD=changeme_in_production
POSTGRES_DB=bijmantra_db

# Redis (Ephemeral Data Storage)
# Used for: background job tracking, search result caching, rate limiting
# Data auto-expires (TTL) - not for persistent storage
# Falls back to in-memory if Redis unavailable (not recommended for production)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
# REDIS_URL=redis://localhost:6379  # Alternative: full URL format

# MinIO (Object Storage)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
MINIO_ENDPOINT=localhost:9000
MINIO_BUCKET=bijmantra-images
MINIO_USE_SSL=false

# Security
# CRITICAL: Generate a secure SECRET_KEY for production!
# Run: python -c "import secrets; print(secrets.token_urlsafe(64))"
# In development, a random key is auto-generated if not set.
# In production (ENVIRONMENT=production), the app will REFUSE TO START without a SECRET_KEY.
SECRET_KEY=
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# CORS
BACKEND_CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]

# File Upload
MAX_UPLOAD_SIZE=10485760  # 10MB in bytes
ALLOWED_IMAGE_TYPES=["image/jpeg","image/png","image/webp"]

# Pagination
DEFAULT_PAGE_SIZE=100
MAX_PAGE_SIZE=1000

# GEMINI API KEY
GEMINI_API_KEY=

# ============================================
# WEATHER API INTEGRATION
# ============================================
# Weather data providers for GDD calculations and climate analysis
# At least one provider recommended for production use

# OpenWeatherMap - Primary weather data provider
# Free tier: 60 calls/minute, 1,000,000 calls/month
# Get key: https://openweathermap.org/api
OPENWEATHERMAP_API_KEY=

# Visual Crossing - Fallback weather data provider
# Free tier: 1,000 calls/day
# Get key: https://www.visualcrossing.com/weather-api
VISUALCROSSING_API_KEY=

# ============================================
# SEEDING CONFIGURATION
# ============================================
# Controls whether demo data seeders run during database initialization.
# Set to false in production to start with an empty database.
# Reference data (breeding methods, scales, traits) is always seeded.
SEED_DEMO_DATA=true

# ============================================
# VEENA AI - LLM Configuration
# ============================================
# Veena supports multiple LLM providers with automatic fallback.
# Configure at least one for intelligent responses.

# --- LOCAL (FREE, PRIVATE) ---
# Ollama - Run LLMs locally (recommended for students)
# Install: https://ollama.ai
# Then run: ollama pull llama3.2:3b
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# --- FREE CLOUD APIs ---
# Groq - Very fast, free tier (30 req/min)
# Get key: https://console.groq.com
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-8b-instant

# Google AI Studio - Good free tier (60 req/min)
# Get key: https://aistudio.google.com
GOOGLE_AI_KEY=
GOOGLE_MODEL=gemini-1.5-flash

# HuggingFace - Free tier available
# Get key: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=
HF_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# FunctionGemma - Function calling (270M, uses HuggingFace API)
# Uses HUGGINGFACE_API_KEY by default, or set separate key
FUNCTIONGEMMA_API_KEY=
FUNCTIONGEMMA_MODEL=google/functiongemma-270m-it

# --- PAID APIs (Optional) ---
# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Anthropic
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-haiku-20240307

# --- FORCE SPECIFIC PROVIDER ---
# Set to force a specific provider (optional)
# Options: ollama, groq, google, huggingface, openai, anthropic, template
# VEENA_LLM_PROVIDER=ollama
