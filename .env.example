# Bijmantra Environment Configuration

# Application
APP_NAME=Bijmantra
APP_VERSION=1.0.0-beta.1
ENVIRONMENT=development

# ============================================
# DEMO ORGANIZATION CONFIGURATION
# ============================================
# Demo data is sandboxed in "Demo Organization" - completely isolated from production.
# Demo users log into this organization and see only demo data.
# Production organizations are never affected by demo data.

# Demo organization name (created by seeders)
DEMO_ORG_NAME=Demo Organization

# Demo user credentials (logs into Demo Organization)
DEMO_USER_EMAIL=demo@bijmantra.org
DEMO_USER_PASSWORD=demo123

# Enable demo data seeding (run: make db-seed)
SEED_DEMO_DATA=true

# Backend API
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
API_V2_PREFIX=/brapi/v2

# Frontend
FRONTEND_PORT=5173
VITE_API_BASE_URL=http://localhost:8000
VITE_DEMO_MODE=true  # Enable demo mode in frontend (shows demo banner, uses demo data)

# Database (PostgreSQL)
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_USER=bijmantra_user
POSTGRES_PASSWORD=changeme_in_production
POSTGRES_DB=bijmantra_db

# Redis (Ephemeral Data Storage)
# Used for: background job tracking, search result caching, rate limiting
# Data auto-expires (TTL) - not for persistent storage
# Falls back to in-memory if Redis unavailable (not recommended for production)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
# REDIS_URL=redis://localhost:6379  # Alternative: full URL format

# MinIO (Object Storage)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
MINIO_ENDPOINT=localhost:9000
MINIO_BUCKET=bijmantra-images
MINIO_USE_SSL=false

# Security
# CRITICAL: Generate a secure SECRET_KEY for production!
# Run: python -c "import secrets; print(secrets.token_urlsafe(64))"
# In development, a random key is auto-generated if not set.
# In production (ENVIRONMENT=production), the app will REFUSE TO START without a SECRET_KEY.
SECRET_KEY=
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# CORS
BACKEND_CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]

# File Upload
MAX_UPLOAD_SIZE=10485760  # 10MB in bytes
ALLOWED_IMAGE_TYPES=["image/jpeg","image/png","image/webp"]

# Pagination
DEFAULT_PAGE_SIZE=100
MAX_PAGE_SIZE=1000

# ============================================
# VEENA AI - LLM Configuration
# ============================================
# Veena supports multiple LLM providers with automatic fallback.
# Configure at least one for intelligent responses.

# --- LOCAL (FREE, PRIVATE) ---
# Ollama - Run LLMs locally (recommended for students)
# Install: https://ollama.ai
# Then run: ollama pull llama3.2:3b
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# --- FREE CLOUD APIs ---
# Groq - Very fast, free tier (30 req/min)
# Get key: https://console.groq.com
GROQ_API_KEY=
GROQ_MODEL=llama-3.1-8b-instant

# Google AI Studio - Good free tier (60 req/min)
# Get key: https://aistudio.google.com
GOOGLE_AI_KEY=
GOOGLE_MODEL=gemini-1.5-flash

# HuggingFace - Free tier available
# Get key: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=
HF_MODEL=mistralai/Mistral-7B-Instruct-v0.2

# FunctionGemma - Function calling (270M, uses HuggingFace API)
# Uses HUGGINGFACE_API_KEY by default, or set separate key
FUNCTIONGEMMA_API_KEY=
FUNCTIONGEMMA_MODEL=google/functiongemma-270m-it

# --- PAID APIs (Optional) ---
# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Anthropic
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-haiku-20240307

# --- FORCE SPECIFIC PROVIDER ---
# Set to force a specific provider (optional)
# Options: ollama, groq, google, huggingface, openai, anthropic, template
# VEENA_LLM_PROVIDER=ollama
