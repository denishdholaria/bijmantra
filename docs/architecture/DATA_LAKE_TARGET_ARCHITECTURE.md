# BijMantra Data Lake â€” Target Architecture

> **Status**: TARGET ARCHITECTURE â€” Not Yet Implemented  
> **Classification**: Roadmap / Vision Document  
> **Current State**: See `DATA_ARCHITECTURE_CURRENT.md`

---

## Document Purpose

This document defines the **intended analytical data architecture** for BijMantra. It describes a target state that will be implemented incrementally alongside the existing PostgreSQL-based operational system.

**This is NOT a description of current implementation.**

For the current, code-verified architecture, see: `DATA_ARCHITECTURE_CURRENT.md`

---

## Architectural Vision

### Core Philosophy

> **Humans read CSV/TSV. Machines work on Parquet. AI thinks in Arrow. APIs speak JSON.**

This principle guides the target state but is **not yet implemented** in the codebase.

### Dual-Plane Architecture

BijMantra is designed to become a **dual-plane system**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BijMantra Dual-Plane                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Operational Plane       â”‚        Analytical Plane           â”‚
â”‚     (OLTP - Current)        â”‚        (OLAP - Target)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PostgreSQL                 â”‚  Parquet files in MinIO           â”‚
â”‚  SQLAlchemy 2.0             â”‚  PyArrow / Polars                 â”‚
â”‚  FastAPI endpoints          â”‚  DuckDB (backend + WASM)          â”‚
â”‚  Real-time CRUD             â”‚  Batch analytics                  â”‚
â”‚  BrAPI v2.1 interface       â”‚  AI feature pipelines             â”‚
â”‚  Row-oriented storage       â”‚  Column-oriented storage          â”‚
â”‚  Transactional integrity    â”‚  Analytical performance           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key insight**: These planes **coexist** â€” the analytical plane augments, not replaces, the operational plane.

---

## Target Data Format Tiers

### Tier 1 â€” External Interface (Ingress / Egress)

**Purpose**: Human-readable data exchange

**Formats**:
- CSV / TSV â€” Researcher exports, spreadsheet compatibility
- JSON â€” API responses, BrAPI payloads

**Rules** (Target State):
- No CSV/TSV used for internal analytics
- No JSON used for bulk data storage
- No schema-less data past ingestion layer

---

### Tier 2 â€” Canonical Analytical Storage

**Purpose**: Persistent analytical datasets

**Format**: Parquet

**Why Parquet**:
- Columnar (optimized for analytical queries)
- Compressed (efficient storage)
- Schema-enforced (type safety)
- Fast scans (predicate pushdown)
- AI-friendly (native Arrow integration)

**Target Rule**:
> All analytical datasets normalized to Parquet for AI/ML pipelines.

---

### Tier 3 â€” Compute Layer

**Purpose**: In-memory analytics and AI processing

**Formats**:
- Apache Arrow â€” Cross-language interchange
- Feather â€” In-memory only (never persisted)

**Rules**:
- Arrow is the interchange format between Python, Rust, JavaScript
- Feather is ephemeral compute format

---

## Target Storage Layout

```
MinIO Buckets (Target Structure)
â”œâ”€â”€ bijmantra-raw/
â”‚   â”œâ”€â”€ phenotype/
â”‚   â”œâ”€â”€ genotype/
â”‚   â”œâ”€â”€ sensor/
â”‚   â”œâ”€â”€ climate/
â”‚   â””â”€â”€ soil/
â”‚
â”œâ”€â”€ bijmantra-normalized/
â”‚   â”œâ”€â”€ phenotype/     (Parquet)
â”‚   â”œâ”€â”€ genotype/      (Parquet)
â”‚   â”œâ”€â”€ sensor/        (Parquet)
â”‚   â”œâ”€â”€ climate/       (Parquet)
â”‚   â””â”€â”€ soil/          (Parquet)
â”‚
â”œâ”€â”€ bijmantra-curated/
â”‚   â”œâ”€â”€ analysis_ready/
â”‚   â”œâ”€â”€ ai_features/
â”‚   â””â”€â”€ reports/
â”‚
â”œâ”€â”€ bijmantra-metadata/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ dictionaries/
â”‚   â””â”€â”€ lineage/
â”‚
â””â”€â”€ bijmantra-images/   (Current - Already Implemented)
```

---

## Target Data Flows

### Ingestion Pipeline (Target)

```
External Data (CSV/TSV/JSON)
         â†“
    Validation Service
         â†“
    Schema Mapping
         â†“
    Type Enforcement
         â†“
    Parquet Write (MinIO)
         â†“
    Catalog Registration
         â†“
    Available for Analytics
```

### Hybrid Query Flow (Target)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Query Router                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OLTP Query?          â”‚  OLAP Query?                    â”‚
â”‚  (CRUD, real-time)    â”‚  (Analytics, bulk)              â”‚
â”‚         â†“             â”‚         â†“                       â”‚
â”‚    PostgreSQL         â”‚    DuckDB + Parquet             â”‚
â”‚         â†“             â”‚         â†“                       â”‚
â”‚    JSON Response      â”‚    Arrow â†’ JSON Response        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AI Pipeline Contract (Target)

```
PostgreSQL â†’ ETL â†’ Parquet â†’ Arrow â†’ Model â†’ JSON
     â†‘                                    â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Predictions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## BrAPI Integration (Target State)

BrAPI remains the **external interface layer**. The analytical plane operates behind it.

### Inbound Flow (Target)

```
BrAPI JSON Payload
         â†“
    Schema Validation
         â†“
    PostgreSQL (operational)
         â†“
    ETL Job (async)
         â†“
    Parquet (analytical)
```

### Outbound Flow (Target)

```
Query Type?
    â”œâ”€â”€ Simple lookup â†’ PostgreSQL â†’ BrAPI JSON
    â””â”€â”€ Analytics â†’ DuckDB/Parquet â†’ BrAPI JSON
```

**Principle**:
> BrAPI defines how data moves. Parquet defines how data lives (analytically).

---

## Schema Governance (Target)

### Required Metadata per Dataset

```yaml
dataset:
  name: trial_observations_2026
  version: v3
  schema_version: 1.2.0
  
fields:
  - name: yield_kg_per_ha
    type: float64
    nullable: false
    unit: kg/ha
    description: Harvested yield per hectare
    domain: phenotype
    
  - name: observation_date
    type: date
    nullable: false
    format: ISO-8601
    
lineage:
  source: postgresql.observations
  transformation: etl_observations_v3
  created: 2026-01-15T00:00:00Z
```

### Versioning Strategy

```
bijmantra-normalized/
  phenotype/
    observations/
      v1/
      v2/
      v3/  â† current
```

- No in-place mutation
- All transformations additive
- Old versions retained for reproducibility

---

## Implementation Roadmap

### Phase 1 â€” OLTP Stabilization (Current)

**Status**: âœ… Complete

- PostgreSQL as source of truth
- BrAPI v2.1 fully implemented
- CRUD workflows operational
- 137 tables, 1,475 endpoints

### Phase 2 â€” Analytical Shadow Layer

**Status**: ðŸ”œ Planned

**Deliverables**:
- [ ] PyArrow / Polars integration in backend
- [ ] MinIO bucket structure for Parquet
- [ ] Nightly ETL: PostgreSQL â†’ Parquet
- [ ] DuckDB backend service for analytics
- [ ] DuckDB-WASM frontend completion

**Dependencies**:
- `pyarrow` or `polars` added to backend
- MinIO bucket policies configured
- ETL scheduler (Celery or similar)

### Phase 3 â€” AI-Native Pipelines

**Status**: ðŸ”œ Planned (Post Phase 2)

**Deliverables**:
- [ ] Arrow-based feature extraction
- [ ] Agent workflow integration (Veena)
- [ ] Real-time + batch fusion queries
- [ ] Cross-domain AI reasoning on Parquet

### Phase 4 â€” Partial Source Shift (Long-Term)

**Status**: ðŸ“‹ Conceptual

**Consideration**:
- High-volume domains (sensor, genotype) may shift to Parquet-first
- PostgreSQL retains transactional roles
- Requires careful evaluation of trade-offs

---

## What Is Explicitly Forbidden (Target State)

Once the analytical plane is implemented:

- âŒ CSV/TSV used for internal analytics
- âŒ JSON blobs used for analytical storage
- âŒ Schema-less datasets in normalized tier
- âŒ Mixing compute formats with storage formats
- âŒ Ad-hoc file naming in data lake

---

## Dependencies for Implementation

| Dependency | Purpose | Status |
|------------|---------|--------|
| PyArrow | Parquet read/write | Not installed |
| Polars | DataFrame operations | Not installed |
| DuckDB | Analytical queries | Stub only |
| Celery/APScheduler | ETL scheduling | Not configured |
| MinIO buckets | Parquet storage | Images only |

---

## Success Criteria

The analytical plane is considered **implemented** when:

1. âœ… Parquet files exist in MinIO for core domains
2. âœ… ETL pipeline runs on schedule
3. âœ… DuckDB queries return results from Parquet
4. âœ… AI pipelines consume Arrow data
5. âœ… Frontend analytics use DuckDB-WASM
6. âœ… BrAPI responses can source from either plane

---

## Governance Alignment

This document:
- Is classified as **TARGET / ROADMAP**
- Does NOT describe current implementation
- Will be updated as phases complete
- Complies with GOVERNANCE.md evidence requirements

**Current state verification**: `DATA_ARCHITECTURE_CURRENT.md`

---

## AI-Era Workflow Principle

> **If data cannot flow in seconds, the workflow is broken.**

This platform is being built for:
- Agent-driven orchestration
- Cross-institution pipelines
- Real-time decision loops

The dual-plane architecture enables this vision while maintaining operational stability.

---

## Engineering Principle

> **Data architecture is system architecture.**

If this layer is wrong, AI will be wrong, analytics will be wrong, and decisions will be wrong.

This document exists to guide that future correctly.

---

*This document describes what WILL BE, not what IS.*
